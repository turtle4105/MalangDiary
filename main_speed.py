import os
import re
import tempfile
import logging
import json
import numpy as np
import soundfile as sf
from datetime import datetime
from typing import List, Dict, Any
from concurrent.futures import ThreadPoolExecutor, as_completed
from fastapi import FastAPI, File, UploadFile, HTTPException, Query
from fastapi.responses import JSONResponse
from openai import OpenAI
from dotenv import load_dotenv
from faster_whisper import WhisperModel
from resemblyzer import VoiceEncoder
import torchaudio
from sklearn.metrics.pairwise import cosine_similarity as sklearn_cosine_similarity

# 1. ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),  # í„°ë¯¸ë„ ì¶œë ¥
        logging.FileHandler('voice_server.log', encoding='utf-8')  # íŒŒì¼ ì¶œë ¥
    ]
)
logger = logging.getLogger(__name__)

# ì²˜ë¦¬ ë‹¨ê³„ë³„ ë¡œê·¸ íŒŒì¼
step_logger = logging.getLogger('steps')
step_handler = logging.FileHandler('processing_steps.log', encoding='utf-8')
step_handler.setFormatter(logging.Formatter('%(asctime)s - %(message)s'))
step_logger.addHandler(step_handler)
step_logger.setLevel(logging.INFO)

# 2. í™˜ê²½ ë³€ìˆ˜ ë¡œë”©
logger.info("=== ì„œë²„ ì´ˆê¸°í™” ì‹œì‘ ===")
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    logger.error("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    raise ValueError("OPENAI_API_KEY is required")
client = OpenAI(api_key=api_key)
logger.info("OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")

# 3. Whisper ëª¨ë¸ ë¡œë”©
try:
    logger.info("Whisper ëª¨ë¸ ë¡œë”© ì‹œì‘ (base, cuda, float16)")
    whisper_model = WhisperModel("base", device="cuda", compute_type="float32")
    logger.info("Whisper ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
except Exception as e:
    logger.error(f"Whisper ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
    raise

# 4. VoiceEncoder ëª¨ë¸ ë¡œë”©
try:
    logger.info("VoiceEncoder ëª¨ë¸ ë¡œë”© ì‹œì‘")
    voice_encoder = VoiceEncoder('cuda')
    logger.info("VoiceEncoder ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
except Exception as e:
    logger.error(f"VoiceEncoder ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
    raise

# 5. ì•„ì´ ìŒì„± ì„ë² ë”© ë¡œë”©
try:
    with open("./data/embedding_inwoo.json", "r") as f:
        embedding_data = json.load(f)
        child_embedding = np.array(embedding_data["embedding"])
    logger.info("ì•„ì´ ìŒì„± ì„ë² ë”© ë¡œë”© ì™„ë£Œ")
except Exception as e:
    logger.error(f"ì•„ì´ ìŒì„± ì„ë² ë”© ë¡œë”© ì‹¤íŒ¨: {e}")
    child_embedding = None

# 6. FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI(title="ìŒì„±ì¸ì‹, ì •ì œ, API")
logger.info("=== ì„œë²„ ì´ˆê¸°í™” ì™„ë£Œ ===")

# 7. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
def cosine_similarity(a: np.ndarray, b: np.ndarray) -> float:
    """ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° (ê¸°ì¡´ ë²„ì „)"""
    norm_a = np.linalg.norm(a)
    norm_b = np.linalg.norm(b)
    if norm_a == 0 or norm_b == 0:
        return 0.0
    return np.dot(a, b) / (norm_a * norm_b)

def process_segment_embedding(segment_audio: np.ndarray, sample_rate: int, child_embedding: np.ndarray, voice_encoder: VoiceEncoder, similarity_threshold: float = 0.68) -> float:
    """ë‹¨ì¼ ì„¸ê·¸ë¨¼íŠ¸ì˜ ì„ë² ë”© ì²˜ë¦¬ ë° ìœ ì‚¬ë„ ê³„ì‚° (ë©”ëª¨ë¦¬ ê¸°ë°˜)"""
    try:
        # ì„¸ê·¸ë¨¼íŠ¸ê°€ ë„ˆë¬´ ì§§ì€ ê²½ìš° íŒ¨ë”©
        min_samples = int(0.5 * sample_rate)  # ìµœì†Œ 0.5ì´ˆ
        if len(segment_audio) < min_samples:
            padding = np.zeros(min_samples - len(segment_audio))
            segment_audio = np.concatenate([segment_audio, padding])
        
        # Resemblyzerìš© ì „ì²˜ë¦¬ (16kHzë¡œ ë¦¬ìƒ˜í”Œë§)
        if sample_rate != 16000:
            import librosa
            segment_audio = librosa.resample(segment_audio, orig_sr=sample_rate, target_sr=16000)
        
        # VoiceEncoderë¡œ ì„ë² ë”© ì¶”ì¶œ (ë©”ëª¨ë¦¬ ê¸°ë°˜)
        embedding = voice_encoder.embed_utterance(segment_audio)
        
        # ìœ ì‚¬ë„ ê³„ì‚° (sklearn ì‚¬ìš©)
        similarity = sklearn_cosine_similarity([embedding], [child_embedding])[0][0]
        
        return float(similarity)
    except Exception as e:
        logger.error(f"ì„¸ê·¸ë¨¼íŠ¸ ì„ë² ë”© ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        return 0.0

def split_audio(audio: np.ndarray, sample_rate: int, segment_duration: float = 2) -> List[Dict]:
    """ì˜¤ë””ì˜¤ë¥¼ 2ì´ˆ ë‹¨ìœ„ë¡œ ë¶„í• """
    segment_samples = int(sample_rate * segment_duration)
    segments = []
    for i in range(0, len(audio), segment_samples):
        start = i
        end = min(i + segment_samples, len(audio))
        segments.append({
            "audio": audio[start:end],
            "start_time": i / sample_rate,
            "end_time": end / sample_rate
        })
    return segments

def has_child_name_calling_pattern(text: str, child_name: str) -> bool:
    """ì•„ì´ ì´ë¦„ì„ í˜¸ëª…í•˜ëŠ” íŒ¨í„´ì´ ìˆëŠ”ì§€ í™•ì¸"""
    if not child_name:
        return False
    
    # ì•„ì´ ì´ë¦„ í˜¸ëª… íŒ¨í„´ë“¤ (ë¶€ëª¨ê°€ ì•„ì´ë¥¼ ë¶€ë¥¼ ë•Œ ì‚¬ìš©)
    calling_patterns = [
        f"{child_name}ì•¼",     # "ì¸ìš°ì•¼"
        f"{child_name}ê°€",     # "ì¸ìš°ê°€" 
        f"{child_name}ëŠ”",     # "ì¸ìš°ëŠ”"
        f"{child_name}ì´",     # "ì¸ìš°ì´"
        f"{child_name}ì•„",     # "ì¸ìš°ì•„"
        f"{child_name} ",      # "ì¸ìš° " (ë’¤ì— ê³µë°±)
        f"{child_name},",      # "ì¸ìš°," (ì‰¼í‘œ)
        f"{child_name}!",      # "ì¸ìš°!" (ëŠë‚Œí‘œ)
        f"{child_name}?",      # "ì¸ìš°?" (ë¬¼ìŒí‘œ)
    ]
    
    # íŒ¨í„´ ì¤‘ í•˜ë‚˜ë¼ë„ í¬í•¨ë˜ë©´ ë¶€ëª¨ ìŒì„±ìœ¼ë¡œ íŒë‹¨
    for pattern in calling_patterns:
        if pattern in text:
            return True
    
    return False

def identify_child_voice_optimized(audio_path: str, segments_list: List, child_name: str = None, similarity_threshold: float = 0.68) -> List[str]:
    """ì•„ì´ì˜ ìŒì„± ì‹ë³„ (ë©”ëª¨ë¦¬ ê¸°ë°˜ + ë³‘ë ¬ ì²˜ë¦¬ + ì´ë¦„ í˜¸ëª… íŒ¨í„´ ê°ì§€)"""
    if child_embedding is None:
        logger.warning("ì•„ì´ ìŒì„± ì„ë² ë”©ì´ ì—†ì–´ì„œ ì „ì²´ í…ìŠ¤íŠ¸ ì‚¬ìš©")
        return [seg.text for seg in segments_list]
    
    try:
        # torchaudioë¡œ ì˜¤ë””ì˜¤ ë¡œë”© (ë” ë¹ ë¦„)
        waveform, sample_rate = torchaudio.load(audio_path)
        audio_data = waveform.squeeze(0).numpy()  # (channels, samples) -> (samples,)
        logger.info(f"ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë”© ì™„ë£Œ: {len(audio_data)} ìƒ˜í”Œ, {sample_rate} Hz")
        
        # Whisper ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì˜¤ë””ì˜¤ ì¶”ì¶œ
        selected_texts = []
        similarity_results = []
        
        def process_whisper_segment(seg):
            """Whisper ì„¸ê·¸ë¨¼íŠ¸ ê¸°ì¤€ìœ¼ë¡œ ì˜¤ë””ì˜¤ ìŠ¬ë¼ì´ì‹± ë° ì„ë² ë”© ì²˜ë¦¬"""
            try:
                # ì‹œê°„ ê¸°ë°˜ ì˜¤ë””ì˜¤ ìŠ¬ë¼ì´ì‹± (ë©”ëª¨ë¦¬ ìƒì—ì„œ)
                start_sample = int(seg.start * sample_rate)
                end_sample = int(seg.end * sample_rate)
                segment_audio = audio_data[start_sample:end_sample]
                
                # ì„ë² ë”© ì²˜ë¦¬
                similarity = process_segment_embedding(
                    segment_audio, sample_rate, child_embedding, voice_encoder, similarity_threshold
                )
                
                # ì•„ì´ ì´ë¦„ í˜¸ëª… íŒ¨í„´ ì²´í¬ (ë¶€ëª¨ ìŒì„± ê°ì§€)
                has_name_calling = has_child_name_calling_pattern(seg.text, child_name)
                
                return {
                    'text': seg.text,
                    'start': seg.start,
                    'end': seg.end,
                    'similarity': similarity,
                    'has_name_calling': has_name_calling,
                    'is_child': (similarity >= similarity_threshold) and not has_name_calling
                }
            except Exception as e:
                logger.error(f"ì„¸ê·¸ë¨¼íŠ¸ ì²˜ë¦¬ ì‹¤íŒ¨ ({seg.start:.2f}-{seg.end:.2f}): {e}")
                has_name_calling = has_child_name_calling_pattern(seg.text, child_name)
                return {
                    'text': seg.text,
                    'start': seg.start,
                    'end': seg.end,
                    'similarity': 0.0,
                    'has_name_calling': has_name_calling,
                    'is_child': False
                }
        
        # ë³‘ë ¬ ì²˜ë¦¬ë¡œ ëª¨ë“  ì„¸ê·¸ë¨¼íŠ¸ ì²˜ë¦¬
        with ThreadPoolExecutor(max_workers=4) as executor:
            futures = [executor.submit(process_whisper_segment, seg) for seg in segments_list]
            
            for future in as_completed(futures):
                result = future.result()
                similarity_results.append(result)
                
                # ë¡œê¹… (ì´ë¦„ í˜¸ëª… ì—¬ë¶€ í¬í•¨)
                name_info = f" (ì´ë¦„í˜¸ëª…: {result.get('has_name_calling', False)})" if child_name else ""
                logger.info(f"ì„¸ê·¸ë¨¼íŠ¸ [{result['start']:.2f}-{result['end']:.2f}]: ìœ ì‚¬ë„ {result['similarity']:.3f} - {'ì•„ì´' if result['is_child'] else 'ì–´ë¥¸'}{name_info}")
                
                # ì•„ì´ ìŒì„±ìœ¼ë¡œ íŒì •ëœ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
                if result['is_child']:
                    selected_texts.append(result['text'])
        
        if not selected_texts:
            logger.warning("ì•„ì´ ìŒì„±ìœ¼ë¡œ ì‹ë³„ëœ êµ¬ê°„ì´ ì—†ì–´ì„œ ì „ì²´ í…ìŠ¤íŠ¸ ì‚¬ìš©")
            return [seg.text for seg in segments_list]
        
        # ì¤‘ë³µ ì œê±° (ìˆœì„œ ìœ ì§€)
        selected_texts = list(dict.fromkeys(selected_texts))
        logger.info(f"ì•„ì´ ìŒì„± ì‹ë³„ ì™„ë£Œ: {len(selected_texts)}ê°œ í…ìŠ¤íŠ¸ ì¶”ì¶œ")
        
        # ìœ ì‚¬ë„ í†µê³„ ë¡œê¹…
        similarities = [r['similarity'] for r in similarity_results]
        child_count = sum(1 for r in similarity_results if r['is_child'])
        logger.info(f"ìœ ì‚¬ë„ í†µê³„ - í‰ê· : {np.mean(similarities):.3f}, ìµœëŒ€: {np.max(similarities):.3f}, ì•„ì´ ìŒì„±: {child_count}/{len(similarity_results)}")
        
        return selected_texts
        
    except Exception as e:
        logger.error(f"ìŒì„± ì‹ë³„ ì‹¤íŒ¨: {e}")
        return [seg.text for seg in segments_list]

def filter_child_voice_manual(segments_list: List, child_name: str = None) -> List[str]:
    """ìˆ˜ë™ìœ¼ë¡œ ì•„ì´ì˜ ìŒì„± íŒ¨í„´ì„ í•„í„°ë§ (ë³´ì¡° ë°©ë²• + ì´ë¦„ í˜¸ëª… íŒ¨í„´ ê°ì§€)"""
    child_texts = []
    
    # ì•„ì´ì˜ ë°œí™”ë¡œ ì¶”ì •ë˜ëŠ” íŒ¨í„´ë“¤ (ì ì ˆí•œ ìˆ˜ì¤€ìœ¼ë¡œ)
    child_patterns = [
        r"^ì‘$|^ë„¤$|^ì•„ë‹ˆì•¼$|^ë§ì•„$|^ìŒ$|^ì–´$",  # ëª…í™•í•œ ë‹¨ë‹µí˜•
        r"^ê³µë¶€í–ˆì–´$|^êµ­ì–´$|^ìˆ˜í•™$|ìˆ˜í•™, íƒí—˜$",  # í•™êµ ê´€ë ¨
        r"^ë”°ê°€ì› ì–´$|^ë”°ê°€ì› ë‹¤$|^ì•„íŒ ì–´$|^ëª©$",  # ëª¸ ìƒíƒœ í‘œí˜„
        r"^ëª°ë¼$|^ëª¨ë¥´ê² ì–´$|^ëª¨ë¥´ê² ë‹¤$|ë­”ì§€ ëª¨ë¥´ê² ë‹¤$",  # ëª¨ë¥´ê² ë‹¤ëŠ” í‘œí˜„
        r"^ìš”êµ¬ë¥´íŠ¸$|^ê¹€ì¹˜$|^ì”ì¹˜êµ­ìˆ˜$|ë°¥ì´ë‘",  # ìŒì‹ ê´€ë ¨
        r"ê³„ì† ë™ë¬¼ì´ ê³„ì† ë°”ë€Œì—ˆì–´$|^ë™ë¬¼",  # ì•„ì´ë‹¤ìš´ í‘œí˜„ë“¤
        r"í•™êµì—ì„œ ê·¸ê±°ë‘ ìˆ˜í•™ ê³µë¶€í•  ë•Œ$|í•™êµì—ì„œ ë†€ì´í™œë™ì´$",  # ì•„ì´ì˜ ê¸´ ë¬¸ì¥ë„ í¬í•¨
    ]
    
    # ì—„ë§ˆ ë°œí™”ë¡œ ì¶”ì •ë˜ëŠ” íŒ¨í„´ë“¤ (ë” í¬ê´„ì ìœ¼ë¡œ ì œì™¸)
    parent_patterns = [
        r".*\?$",  # ì§ˆë¬¸ë¬¸
        r"ëŒ€ë‹µì„|ë…¹ìŒì´|ì—„ë§ˆë‘|ëŒ€í™”í•˜ëŠ”|í•´ì•¼|í•˜ë©´|í•˜ì|í• ê¹Œ|í•´ë´",  # ì§€ì‹œ/ì œì•ˆ ì–´íˆ¬  
        r"ì„¤ì•„|ì„œì•„",  # ì•„ì´ ì´ë¦„ í˜¸ëª… (ê¸°ë³¸ê°’)
        r"ë­í–ˆì–´|ë­ ë°°ì› ì–´|ì–´ë–»ê²Œ|ì™œ|ë¬´ìŠ¨|ì–´ë””|ì–¸ì œ",  # ì§ˆë¬¸ í‚¤ì›Œë“œ
        r"í¬ê²Œ|ì–˜ê¸°|ì‹œê°„ì—|ë§ê³ |ë˜|ë‹¤ë¥¸|íŠ¹ë³„í•œ|ì˜|ì•ˆ|ëª»",  # ì—„ë§ˆ ì–´íˆ¬
        r"ë‚˜ì™”ì–´|ë‚˜ì˜¤ì§€|ë°˜ì°¬|ê¸‰ì‹|ì•„ì´ìŠ¤í¬ë¦¼|ë§ì´|ë§¤ì¼",  # ìŒì‹ ê´€ë ¨ ì§ˆë¬¸
        r"ì¼ì°|ìì•¼|ëˆ„ì›Œì„œ|ë‚´ì¼|í•™êµ|ê°€ì„œ|ì œì¼|ì¦ê±°ì› ì–´|í˜ë“¤ì—ˆì–´",  # ì¼ìƒ ê´€ë¦¬
        r"ì•Œì•˜ì–´|ì˜ ì|ê·¸ë ‡êµ¬ë‚˜|ê·¸ëŸ¼|ì´ìœ ê°€|ë­˜ê¹Œ",  # ì—„ë§ˆ ë°˜ì‘
        r"^[ê°€-í£]{7,}$",  # 7ê¸€ì ì´ìƒì˜ ê¸´ ë¬¸ì¥
    ]
    
    for seg in segments_list:
        text = seg.text.strip()
        
        # ë„ˆë¬´ ì§§ì€ í…ìŠ¤íŠ¸ ì œì™¸
        if len(text) < 2:
            continue
        
        # ì•„ì´ ì´ë¦„ í˜¸ëª… íŒ¨í„´ ì²´í¬ (ë¶€ëª¨ ìŒì„±ìœ¼ë¡œ íŒë‹¨)
        if child_name and has_child_name_calling_pattern(text, child_name):
            logger.debug(f"ì´ë¦„ í˜¸ëª… íŒ¨í„´ ê°ì§€ë¡œ ì œì™¸: '{text}'")
            continue
            
        # ì—„ë§ˆ íŒ¨í„´ ì²´í¬
        is_parent = False
        for pattern in parent_patterns:
            if re.search(pattern, text):
                is_parent = True
                break
                
        if is_parent:
            continue
            
        # ì•„ì´ íŒ¨í„´ ì²´í¬
        is_child = False
        for pattern in child_patterns:
            if re.search(pattern, text):
                is_child = True
                break
                
        # ì§§ì€ ë‹¨ë‹µí˜•ì´ê±°ë‚˜ ì•„ì´ íŒ¨í„´ì— ë§ìœ¼ë©´ í¬í•¨
        # ë˜ëŠ” ë§¤ìš° ì§§ì€ ë‹¨ë‹µí˜• (ì‘, ë„¤, ìŒ ë“±)ì€ ë¬´ì¡°ê±´ í¬í•¨
        if is_child or len(text) <= 2 or (len(text) <= 4 and not is_parent):
            child_texts.append(text)
    
    logger.info(f"ìˆ˜ë™ í•„í„°ë§ ê²°ê³¼: {len(child_texts)}ê°œ í…ìŠ¤íŠ¸ ì¶”ì¶œ")
    return child_texts

# 8. íƒ€ì„ìŠ¤íƒ¬í”„ ì œê±° í•¨ìˆ˜
def remove_timestamps(text: str) -> str:
    logger.debug(f"íƒ€ì„ìŠ¤íƒ¬í”„ ì œê±° ì „: {text[:100]}...")
    text = re.sub(r"\[\d{2}:\d{2}(?:\.\d{2,})?\]\s*", "", text)
    result = re.sub(r"\s+", " ", text).strip()
    logger.debug(f"íƒ€ì„ìŠ¤íƒ¬í”„ ì œê±° í›„: {result[:100]}...")
    return result

# 6. ë‹¨ìˆœ í…ìŠ¤íŠ¸ ì •ë¦¬ í•¨ìˆ˜ (GPT ì—†ì´)
def simple_text_cleanup(text: str) -> str:
    """GPT ì—†ì´ ë‹¨ìˆœí•œ ì˜¤íƒ€ ìˆ˜ì •ë§Œ ìˆ˜í–‰"""
    logger.info(f"ë‹¨ìˆœ í…ìŠ¤íŠ¸ ì •ë¦¬ ì‹œì‘ - ì…ë ¥ ê¸¸ì´: {len(text)} ë¬¸ì")
    
    # ì•Œë ¤ì§„ ì˜¤íƒ€ íŒ¨í„´ ìˆ˜ì •
    replacements = {
        "í˜•ë‚´ë„¤": "í‰ë‚´ë‚´",
        "í˜•ë‚´ë‚´": "í‰ë‚´ë‚´", 
        "ë°˜ê³¼í›„": "ë°©ê³¼í›„",
        "ê¹Œë¹ ": "ê¹Œë¨¹ì–´",
        "ë”°ê°€ì› ë‹¤": "ë”°ê°€ì› ì–´",
        "ì´ë”°ê°€": "ë”°ê°€",
        "ë†€ì´í•  ë™ì•ˆê°€": "ë†€ì´í™œë™ì´",
        "ê¸€ì”¨ ìª„ì¤€ ê±°": "ê¸€ì”¨ ì“°ëŠ” ê±°"
    }
    
    result = text
    for old, new in replacements.items():
        result = result.replace(old, new)
    
    # ë¶ˆí•„ìš”í•œ ê³µë°± ì •ë¦¬
    result = re.sub(r'\s+', ' ', result).strip()
    
    logger.info(f"ë‹¨ìˆœ í…ìŠ¤íŠ¸ ì •ë¦¬ ì™„ë£Œ - ì¶œë ¥ ê¸¸ì´: {len(result)} ë¬¸ì")
    return result

# 7. í†µí•© ì¼ê¸° + ê°ì • ìƒì„± í•¨ìˆ˜ (GPT 1íšŒ í˜¸ì¶œ)
def generate_diary_with_emotions(child_text: str, full_context: str) -> dict:
    logger.info(f"ì¼ê¸°+ê°ì • í†µí•© ìƒì„± ì‹œì‘ - ì•„ì´ ë°œí™” ê¸¸ì´: {len(child_text)} / ì „ì²´ ë§¥ë½ ê¸¸ì´: {len(full_context)}")
    
    prompt = f"""
 ì „ì²´ ë°œí™” ë‚´ìš©ì„ GPTê°€ ì¼ê¸° ì‘ì„± ì‹œ ë§¥ë½ ì´í•´ì— í™œìš©í•´ì•¼ í•œë‹¤.í•˜ì§€ë§Œ ì‹¤ì œ ì¼ê¸° í…ìŠ¤íŠ¸ ë‚´ìš©ì€ ì•„ì´ì˜ ë°œí™”ë§Œì´ ì•„ë‹Œ ì „ì²´ë§¥ë½ì„ ë°°ê²½ìœ¼ë¡œ ì•„ì´ì˜ ë°œí™”ë‚´ìš©ì˜ í…ìŠ¤íŠ¸ë¥¼ ì´ìš©í•´ ì•„ì´ ì…ì¥ì—ì„œ ìì—°ìŠ¤ëŸ¬ìš´ ì¼ê¸°ê°€ ìƒì„±ë˜ì–´ì•¼ í•œë‹¤.
1. ì¼ê¸° ì œëª© (ì•„ì´ ì‹œì„ ì—ì„œ ê°„ë‹¨íˆ)
2. ì¼ê¸° ë‚´ìš© (ì „ì²´ì ì¸ ë§¥ë½ì—ì„œ ì•„ì´ì˜ ì‹œì ìœ¼ë¡œ  ì„œìˆ )
3. ê°ì • í‚¤ì›Œë“œ (ìµœì†Œ 1ê°œ, ìµœëŒ€ 5ê°œ, ì‰¼í‘œë¡œ êµ¬ë¶„)

**ì ˆëŒ€ ê¸ˆì§€ì‚¬í•­:**
- ì—†ëŠ” ë‚´ìš©ì„ ì¶”ê°€í•˜ê±°ë‚˜ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”
- ì‹œê°„ëŒ€ë¥¼ ì„ì˜ë¡œ ì •í•˜ì§€ ë§ˆì„¸ìš” (ì ì‹¬/ì €ë… ë“±)
- ì¥ì†Œë‚˜ ìƒí™©ì„ ë§Œë“¤ì–´ë‚´ì§€ ë§ˆì„¸ìš”
- ì•„ì´ê°€ ë§í•˜ì§€ ì•Šì€ ê°ì •ì´ë‚˜ ìƒê°ì„ ì“°ì§€ ë§ˆì„¸ìš”

**ì‘ì„± ë°©ë²•:**
- ì•„ì´ê°€ ì‹¤ì œ ë§í•œ ë‚´ìš©ë§Œ ê·¸ëŒ€ë¡œ í™œìš©
- ê°„ë‹¨í•œ ë¬¸ì¥ìœ¼ë¡œ ë‚˜ì—´ì‹ ì‘ì„±
- ë¶€ì¡±í•´ë„ ì¶”ê°€í•˜ì§€ ë§ê³  ê·¸ëŒ€ë¡œ ì‘ì„±

[ì „ì²´ ëŒ€í™” ë§¥ë½]
{full_context}

[ì•„ì´ ë°œí™” ë‚´ìš©]
{child_text}

--- ì¶œë ¥ í˜•ì‹ ì˜ˆì‹œ ---
ì œëª©: ì¹œêµ¬ë‘ ë†€ì•„ì„œ ì¦ê±°ìš´ ë‚  ğŸ˜Š  
ë‚´ìš©: ì˜¤ëŠ˜ì€ ì¹œêµ¬ë‘ ë†€ì´í„°ì—ì„œ ë†€ì•˜ë‹¤...  
ê°ì •: ê¸°ì¨, ì‹ ë‚¨, í”¼ê³¤í•¨"""
    
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.5,
        )
        response_text = response.choices[0].message.content.strip()
        
        # ì•ˆì „í•œ í† í° ë¡œê¹…
        try:
            if hasattr(response, 'usage') and response.usage:
                tokens = response.usage.total_tokens
                logger.info(f"í†µí•© ìƒì„± ì™„ë£Œ - ê¸¸ì´: {len(response_text)} ë¬¸ì, í† í°: {tokens}")
            else:
                logger.info(f"í†µí•© ìƒì„± ì™„ë£Œ - ê¸¸ì´: {len(response_text)} ë¬¸ì")
        except Exception as log_error:
            logger.info(f"í†µí•© ìƒì„± ì™„ë£Œ - ê¸¸ì´: {len(response_text)} ë¬¸ì (í† í° ë¡œê¹… ì‹¤íŒ¨: {log_error})")
        
        # ì‘ë‹µ íŒŒì‹±
        import re
        
        # ì •ê·œì‹ìœ¼ë¡œ ì œëª©, ë‚´ìš©, ê°ì • ì¶”ì¶œ
        title_match = re.search(r"ì œëª©:\s*(.*)", response_text)
        content_match = re.search(r"ë‚´ìš©:\s*(.*?)(?=\nê°ì •:|$)", response_text, re.DOTALL)
        emotion_match = re.search(r"ê°ì •:\s*(.*)", response_text)
        
        title = title_match.group(1).strip() if title_match else "ì¼ê¸° ì œëª©"
        content = content_match.group(1).strip() if content_match else response_text
        emotions_str = emotion_match.group(1).strip() if emotion_match else "ê¸°ì¨"
        
        # ê°ì •ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        emotions = [e.strip() for e in emotions_str.split(",") if e.strip()]
        
        result = {
            "title": title,
            "content": content,
            "emotions": emotions
        }
        
        logger.info(f"ì¼ê¸°+ê°ì • í†µí•© ìƒì„± ì™„ë£Œ - ì œëª©: {title}, ê°ì •: {emotions}")
        return result
        
    except Exception as e:
        logger.error(f"ì¼ê¸°+ê°ì • í†µí•© ìƒì„± ì‹¤íŒ¨: {e}")
        # í´ë°±ìœ¼ë¡œ ê¸°ë³¸ê°’ ë°˜í™˜
        return {
            "title": "ì¼ê¸° ìƒì„± ì‹¤íŒ¨",
            "content": child_text if child_text else "ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.",
            "emotions": ["ê¶ê¸ˆí•¨"]
        }

# 9. /transcribe POST API
@app.post("/transcribe")
async def transcribe(file: UploadFile = File(...), child_name: str = Query(None)):
    request_id = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
    logger.info(f"=== ìƒˆë¡œìš´ ìš”ì²­ ì‹œì‘ [{request_id}] ===")
    if child_name:
        logger.info(f"[{request_id}] ì•„ì´ ì´ë¦„: '{child_name}' - í˜¸ëª… íŒ¨í„´ ê°ì§€ í™œì„±í™”")
    step_logger.info(f"REQUEST {request_id}: ìƒˆë¡œìš´ transcribe ìš”ì²­ (ì•„ì´ ì´ë¦„: {child_name})")
    
    # íŒŒì¼ ê²€ì¦
    logger.info(f"ì—…ë¡œë“œëœ íŒŒì¼: {file.filename}, í¬ê¸°: {file.size} bytes, íƒ€ì…: {file.content_type}")
    if not file.content_type or not file.content_type.startswith('audio/'):
        logger.warning(f"ì˜ëª»ëœ íŒŒì¼ íƒ€ì…: {file.content_type}")
        step_logger.error(f"REQUEST {request_id}: ì˜ëª»ëœ íŒŒì¼ íƒ€ì… - {file.content_type}")
        raise HTTPException(status_code=400, detail="Audio file required")

    # ì„ì‹œ íŒŒì¼ ìƒì„±
    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
        audio_data = await file.read()
        tmp.write(audio_data)
        tmp_path = tmp.name
        logger.info(f"ì„ì‹œ ì˜¤ë””ì˜¤ íŒŒì¼ ìƒì„±: {tmp_path}")
        step_logger.info(f"REQUEST {request_id}: ì„ì‹œ íŒŒì¼ ìƒì„± - {tmp_path}")

    try:
        # STEP 1: Whisper ì „ì‚¬
        logger.info(f"[{request_id}] STEP 1: Whisper ì „ì‚¬ ì‹œì‘")
        step_logger.info(f"REQUEST {request_id}: STEP 1 - Whisper ì „ì‚¬ ì‹œì‘")
        
        segments, _ = whisper_model.transcribe(tmp_path, beam_size=5,vad_filter=True)
        segments_list = list(segments)

        
        logger.info(f"[{request_id}] Whisper ì „ì‚¬ ì™„ë£Œ - {len(segments_list)}ê°œ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ì¶œ")
        step_logger.info(f"REQUEST {request_id}: STEP 1 ì™„ë£Œ - {len(segments_list)}ê°œ ì„¸ê·¸ë¨¼íŠ¸")
        
        if not segments_list:
            logger.warning(f"[{request_id}] ìŒì„±ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            step_logger.error(f"REQUEST {request_id}: STEP 1 ì‹¤íŒ¨ - í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨")
            raise HTTPException(status_code=400, detail="No speech detected")
        
        # ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´ ë¡œê¹…
        for i, segment in enumerate(segments_list[:3]):  # ì²˜ìŒ 3ê°œë§Œ ë¡œê¹…
            logger.debug(f"[{request_id}] ì„¸ê·¸ë¨¼íŠ¸ {i+1}: [{segment.start:.2f}-{segment.end:.2f}] {segment.text[:50]}...")
        
        raw_text = " ".join([f"[{s.start:.2f}] {s.text}" for s in segments_list])
        logger.info(f"[{request_id}] ì›ë³¸ í…ìŠ¤íŠ¸ ìƒì„± - ê¸¸ì´: {len(raw_text)} ë¬¸ì")
        step_logger.info(f"REQUEST {request_id}: ì›ë³¸ í…ìŠ¤íŠ¸ ìƒì„± - {raw_text[:100]}...")
        
        # STEP 2: íƒ€ì„ìŠ¤íƒ¬í”„ ì œê±°
        logger.info(f"[{request_id}] STEP 2: íƒ€ì„ìŠ¤íƒ¬í”„ ì œê±°")
        step_logger.info(f"REQUEST {request_id}: STEP 2 - íƒ€ì„ìŠ¤íƒ¬í”„ ì œê±°")
        whisper_text = remove_timestamps(raw_text)
        logger.info(f"[{request_id}] íƒ€ì„ìŠ¤íƒ¬í”„ ì œê±° ì™„ë£Œ - ì •ì œëœ ê¸¸ì´: {len(whisper_text)} ë¬¸ì")
        step_logger.info(f"REQUEST {request_id}: STEP 2 ì™„ë£Œ - ì •ì œëœ í…ìŠ¤íŠ¸: {whisper_text[:100]}...")

        # STEP 3: ì„¸ê·¸ë¨¼íŠ¸ ë¶„í•  ë° ìŒì„± ì‹ë³„
        logger.info(f"[{request_id}] STEP 3: ìŒì„± ì‹ë³„ ë‹¨ê³„")
        step_logger.info(f"REQUEST {request_id}: STEP 3 - ìŒì„± ì‹ë³„ ì‹œì‘")
        
        # ì „ì²´ ë§¥ë½ ì´í•´ë¥¼ ìœ„í•œ ì „ì²´ í…ìŠ¤íŠ¸ ìƒì„±
        full_context = " ".join([seg.text for seg in segments_list])
        logger.info(f"[{request_id}] ì „ì²´ ë§¥ë½ í…ìŠ¤íŠ¸ ìƒì„± - ê¸¸ì´: {len(full_context)} ë¬¸ì")
        
        # ì•„ì´ì˜ ìŒì„±ë§Œ ì‹ë³„ (ìµœì í™”ëœ ë©”ëª¨ë¦¬ ê¸°ë°˜ ë°©ì‹ + ì´ë¦„ í˜¸ëª… íŒ¨í„´ ê°ì§€)
        if child_name:
            logger.info(f"[{request_id}] ì•„ì´ ì´ë¦„ ì„¤ì •: '{child_name}' - í˜¸ëª… íŒ¨í„´ ê°ì§€ í™œì„±í™”")
        child_texts = identify_child_voice_optimized(tmp_path, segments_list, child_name, similarity_threshold=0.68)
        child_only_text = " ".join(child_texts)
        
        logger.info(f"[{request_id}] ì•„ì´ ìŒì„± ì‹ë³„ ì™„ë£Œ - ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ìˆ˜: {len(child_texts)}")
        logger.info(f"[{request_id}] ì•„ì´ ìŒì„± ë‚´ìš©: {child_only_text}")
        step_logger.info(f"REQUEST {request_id}: STEP 3 ì™„ë£Œ - ì•„ì´ ìŒì„±: {child_only_text[:100]}...")
        
        # STEP 4: í…ìŠ¤íŠ¸ ì •ì œ (ë‹¨ìˆœ ì˜¤íƒ€ ìˆ˜ì •ë§Œ)
        logger.info(f"[{request_id}] STEP 4: í…ìŠ¤íŠ¸ ì •ì œ ë‹¨ê³„ (ì˜¤íƒ€ ìˆ˜ì •ë§Œ)")
        step_logger.info(f"REQUEST {request_id}: STEP 4 - í…ìŠ¤íŠ¸ ì •ì œ ì‹œì‘")
        refined_text = simple_text_cleanup(whisper_text)

        # STEP 5: í†µí•© ì¼ê¸°+ê°ì • ìƒì„± (GPT 1íšŒ í˜¸ì¶œ)
        logger.info(f"[{request_id}] STEP 5: ì¼ê¸°+ê°ì • í†µí•© ìƒì„± ë‹¨ê³„")
        step_logger.info(f"REQUEST {request_id}: STEP 5 - ì¼ê¸°+ê°ì • í†µí•© ìƒì„± ì‹œì‘")
        diary_result = generate_diary_with_emotions(child_only_text, full_context)

        # STEP 6: ê²°ê³¼ ë°˜í™˜ (ê¸°ì¡´ í¬ë§· í˜¸í™˜)
        result = {
            "transcript": whisper_text,  # ì „ì²´ ì›ë³¸ í…ìŠ¤íŠ¸ ë°˜í™˜ (íƒ€ì„ìŠ¤íƒ¬í”„ ì œê±°ëœ)
            "refined_transcript": refined_text,  # GPTë¡œ ì •ì œëœ í…ìŠ¤íŠ¸ (ì˜¤íƒ€ ìˆ˜ì •ë§Œ)
            "child_voice_only": child_only_text,  # ì•„ì´ ë°œí™”ë§Œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸
            "emotion": ", ".join(diary_result["emotions"]),  # ê¸°ì¡´ í¬ë§·: ë¬¸ìì—´
            "diary": {  # ê¸°ì¡´ í¬ë§·: ê°ì²´
                "title": diary_result["title"],
                "content": diary_result["content"]
            }
        }
        
        logger.info(f"[{request_id}] === ìš”ì²­ ì²˜ë¦¬ ì™„ë£Œ ===")
        step_logger.info(f"REQUEST {request_id}: ëª¨ë“  ë‹¨ê³„ ì™„ë£Œ - ê²°ê³¼ ë°˜í™˜")
        
        # ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œë„ ì €ì¥
        result_filename = f"result_{request_id}.json"
        try:
            with open(result_filename, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            logger.info(f"[{request_id}] ê²°ê³¼ íŒŒì¼ ì €ì¥: {result_filename}")
        except Exception as e:
            logger.warning(f"[{request_id}] ê²°ê³¼ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
        
        return JSONResponse(result)

    except Exception as e:
        logger.error(f"[{request_id}] ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        step_logger.error(f"REQUEST {request_id}: ì¹˜ëª…ì  ì˜¤ë¥˜ - {e}")
        raise HTTPException(status_code=500, detail=f"Processing error: {str(e)}")
    
    finally:
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        if os.path.exists(tmp_path):
            os.remove(tmp_path)
            logger.debug(f"[{request_id}] ì„ì‹œ íŒŒì¼ ì‚­ì œ: {tmp_path}")
            step_logger.info(f"REQUEST {request_id}: ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ")

# ì„œë²„ ì‹œì‘ ì‹œ ë¡œê¹…
if __name__ == "__main__":
    import uvicorn
    logger.info("=== ì„œë²„ ì‹œì‘ ===")
    uvicorn.run(app, host="0.0.0.0", port=8000)